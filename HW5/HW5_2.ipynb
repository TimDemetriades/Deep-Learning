{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5_2 - Tim Demetriades\n",
    "## Examine the Impact of Regularization and Dropout\n",
    "10/3/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's build the base model using the default configuration for fashion_mnist from HW4.\n",
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate deeplearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ad hoc mnist instances\n",
    "from keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# load (downloaded if needed) the fashion_MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.5119 - accuracy: 0.8225 - val_loss: 0.4165 - val_accuracy: 0.8510\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.3711 - accuracy: 0.8673 - val_loss: 0.3822 - val_accuracy: 0.8629\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.3349 - accuracy: 0.8791 - val_loss: 0.3562 - val_accuracy: 0.8729\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.3072 - accuracy: 0.8886 - val_loss: 0.3814 - val_accuracy: 0.8688\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.2854 - accuracy: 0.8952 - val_loss: 0.3600 - val_accuracy: 0.8699\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2696 - accuracy: 0.9006 - val_loss: 0.3531 - val_accuracy: 0.8775\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2543 - accuracy: 0.9065 - val_loss: 0.3211 - val_accuracy: 0.8846\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2443 - accuracy: 0.9102 - val_loss: 0.3100 - val_accuracy: 0.8875\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2320 - accuracy: 0.9148 - val_loss: 0.3449 - val_accuracy: 0.8786\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2228 - accuracy: 0.9170 - val_loss: 0.3298 - val_accuracy: 0.8826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20143341ac0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 11.74%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see the base model finished with a **Baseline Error of 11.74%** and the following metrics after 10 epochs:\n",
    "- Training Loss: 0.2228\n",
    "- Testing Loss:  0.3298\n",
    "- Training Accuracy: 91.70%\n",
    "- Testing Accuracy:  88.26%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try adding **Regularization** to the model.\n",
    "\n",
    "### Adding L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regularized model\n",
    "def regularized_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the regularized model\n",
    "model = regularized_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.7762 - accuracy: 0.8270 - val_loss: 0.5733 - val_accuracy: 0.8490\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.4712 - accuracy: 0.8699 - val_loss: 0.4598 - val_accuracy: 0.8605\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.3864 - accuracy: 0.8823 - val_loss: 0.4003 - val_accuracy: 0.8734\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.3505 - accuracy: 0.8878 - val_loss: 0.3788 - val_accuracy: 0.8756\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.3274 - accuracy: 0.8935 - val_loss: 0.3797 - val_accuracy: 0.8748\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.3109 - accuracy: 0.8976 - val_loss: 0.3687 - val_accuracy: 0.8796\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.2941 - accuracy: 0.9032 - val_loss: 0.3585 - val_accuracy: 0.8835\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.2836 - accuracy: 0.9062 - val_loss: 0.3507 - val_accuracy: 0.8829\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.2769 - accuracy: 0.9083 - val_loss: 0.3720 - val_accuracy: 0.8774\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.2676 - accuracy: 0.9123 - val_loss: 0.3503 - val_accuracy: 0.8862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20143c27c70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 11.38%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see the **l2 regularized model** finished with a **Baseline Error of 11.38%**, which is slightly less than the baseline error of the base model, and the following metrics after 10 epochs:\n",
    "- Training Loss: 0.2676\n",
    "- Testing Loss:  0.3503\n",
    "- Training Accuracy: 91.23%\n",
    "- Testing Accuracy:  88.62%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These metrics are pretty similar to that of the baseline model, and if anything actually slightly worse. Let's try to adjust the regularization factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regularized model\n",
    "def regularized_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the regularized model\n",
    "model = regularized_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.3906 - accuracy: 0.8141 - val_loss: 0.5730 - val_accuracy: 0.8330\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4743 - accuracy: 0.8582 - val_loss: 0.4844 - val_accuracy: 0.8517\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.4252 - accuracy: 0.8684 - val_loss: 0.4722 - val_accuracy: 0.8488\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.3901 - accuracy: 0.8786 - val_loss: 0.4462 - val_accuracy: 0.8562\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.3718 - accuracy: 0.8819 - val_loss: 0.4219 - val_accuracy: 0.8661\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.3657 - accuracy: 0.8847 - val_loss: 0.4074 - val_accuracy: 0.8673\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.3483 - accuracy: 0.8895 - val_loss: 0.4045 - val_accuracy: 0.8720\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.3361 - accuracy: 0.8934 - val_loss: 0.3950 - val_accuracy: 0.8747\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.3307 - accuracy: 0.8952 - val_loss: 0.3733 - val_accuracy: 0.8768\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.3157 - accuracy: 0.9004 - val_loss: 0.3892 - val_accuracy: 0.8751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201440458b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 12.49%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the baseline error is even worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see the **l2 regularized model with 0.01 regularization factor** finished with a **Baseline Error of 12.49%**, which is **higher** than the baseline error of the base model, and the following metrics after 10 epochs:\n",
    "- Training Loss: 0.3157\n",
    "- Testing Loss:  0.3892\n",
    "- Training Accuracy: 90.04%\n",
    "- Testing Accuracy:  87.51%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model actually performed worse. Let's try decreasing the regularization factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regularized model\n",
    "def regularized_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0001), activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the regularized model\n",
    "model = regularized_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.5353 - accuracy: 0.8285 - val_loss: 0.4994 - val_accuracy: 0.8331\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.3912 - accuracy: 0.8724 - val_loss: 0.4279 - val_accuracy: 0.8563\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.3468 - accuracy: 0.8849 - val_loss: 0.3850 - val_accuracy: 0.8753\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.3231 - accuracy: 0.8926 - val_loss: 0.3742 - val_accuracy: 0.8742\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.3033 - accuracy: 0.8989 - val_loss: 0.3793 - val_accuracy: 0.8726\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2828 - accuracy: 0.9053 - val_loss: 0.3466 - val_accuracy: 0.8843\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.2730 - accuracy: 0.9080 - val_loss: 0.3533 - val_accuracy: 0.8821\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.2591 - accuracy: 0.9118 - val_loss: 0.3548 - val_accuracy: 0.8818\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.2485 - accuracy: 0.9155 - val_loss: 0.3409 - val_accuracy: 0.8867\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.2339 - accuracy: 0.9206 - val_loss: 0.3313 - val_accuracy: 0.8917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20143a4f970>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 10.83%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see the **l2 regularized model with 0.0001 regularization factor** finished with a **Baseline Error of 10.83%**, which is **lower** than the baseline error of the base model, and the following metrics after 10 epochs:\n",
    "- Training Loss: 0.2339\n",
    "- Testing Loss:  0.3313\n",
    "- Training Accuracy: 92.06%\n",
    "- Testing Accuracy:  89.17%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performed the best of the 3. Decreasing the regularization factor to 0.0001 improved the baseline error (10.83%). Also, all the losses and accuracy have improved. This makes sense, as regularization tends to improve model performance by preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dropout model\n",
    "def dropout_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dropout model\n",
    "model = dropout_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5747 - accuracy: 0.7980 - val_loss: 0.4503 - val_accuracy: 0.8372\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4189 - accuracy: 0.8496 - val_loss: 0.4029 - val_accuracy: 0.8536\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3833 - accuracy: 0.8613 - val_loss: 0.3851 - val_accuracy: 0.8625\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3629 - accuracy: 0.8675 - val_loss: 0.3674 - val_accuracy: 0.8681\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3465 - accuracy: 0.8725 - val_loss: 0.3591 - val_accuracy: 0.8740\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3319 - accuracy: 0.8780 - val_loss: 0.3473 - val_accuracy: 0.8733\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3234 - accuracy: 0.8815 - val_loss: 0.3453 - val_accuracy: 0.8773\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3120 - accuracy: 0.8855 - val_loss: 0.3373 - val_accuracy: 0.8763\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3068 - accuracy: 0.8873 - val_loss: 0.3261 - val_accuracy: 0.8812\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.2989 - accuracy: 0.8890 - val_loss: 0.3395 - val_accuracy: 0.8738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2014508e2b0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 12.62%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see the **dropout layer** finished with a **Baseline Error of 12.62%**, which is **higher** than the baseline error of the base model, and the following metrics after 10 epochs:\n",
    "- Training Loss: 0.2989\n",
    "- Testing Loss:  0.3395\n",
    "- Training Accuracy: 88.90%\n",
    "- Testing Accuracy:  87.38%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model with a dropout layer performed worse than the base model. Let's try using a different dropout rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dropout model\n",
    "def dropout_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dropout model\n",
    "model = dropout_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5327 - accuracy: 0.8133 - val_loss: 0.4383 - val_accuracy: 0.8424\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3910 - accuracy: 0.8602 - val_loss: 0.3817 - val_accuracy: 0.8652\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3491 - accuracy: 0.8744 - val_loss: 0.3640 - val_accuracy: 0.8695\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3268 - accuracy: 0.8810 - val_loss: 0.3517 - val_accuracy: 0.8748\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3078 - accuracy: 0.8872 - val_loss: 0.3467 - val_accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.2955 - accuracy: 0.8897 - val_loss: 0.3335 - val_accuracy: 0.8770\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.2842 - accuracy: 0.8946 - val_loss: 0.3301 - val_accuracy: 0.8812\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.2738 - accuracy: 0.8984 - val_loss: 0.3450 - val_accuracy: 0.8719\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.2644 - accuracy: 0.9028 - val_loss: 0.3230 - val_accuracy: 0.8844\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.2581 - accuracy: 0.9044 - val_loss: 0.3262 - val_accuracy: 0.8813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20150dcc400>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 11.87%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see the **dropout layer with a rate of 0.25** finished with a **Baseline Error of 11.87%**, which is slightly **higher** than the baseline error of the base model but lower than the baseline error of the other dropout model, and the following metrics after 10 epochs:\n",
    "- Training Loss: 0.2281\n",
    "- Testing Loss:  0.3262\n",
    "- Training Accuracy: 90.44%\n",
    "- Testing Accuracy:  88.13%\n",
    "\n",
    "Let's try now with a higher dropout rate - 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dropout model\n",
    "def dropout_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.75))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dropout model\n",
    "model = dropout_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6840 - accuracy: 0.7582 - val_loss: 0.4772 - val_accuracy: 0.8317\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4975 - accuracy: 0.8216 - val_loss: 0.4295 - val_accuracy: 0.8439\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4581 - accuracy: 0.8335 - val_loss: 0.4086 - val_accuracy: 0.8517\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4354 - accuracy: 0.8401 - val_loss: 0.3917 - val_accuracy: 0.8570\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4225 - accuracy: 0.8466 - val_loss: 0.3886 - val_accuracy: 0.8588\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4094 - accuracy: 0.8501 - val_loss: 0.3716 - val_accuracy: 0.8652\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4004 - accuracy: 0.8532 - val_loss: 0.3756 - val_accuracy: 0.8644\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3925 - accuracy: 0.8570 - val_loss: 0.3638 - val_accuracy: 0.8690\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3848 - accuracy: 0.8574 - val_loss: 0.3579 - val_accuracy: 0.8728\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3781 - accuracy: 0.8619 - val_loss: 0.3577 - val_accuracy: 0.8694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20151104940>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 13.06%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see the **dropout layer with a rate of 0.75** finished with a **Baseline Error of 13.06%**, which is **higher** than the baseline error of the base model and the other dropout models, and the following metrics after 10 epochs:\n",
    "- Training Loss: 0.3781\n",
    "- Testing Loss:  0.3577\n",
    "- Training Accuracy: 86.19%\n",
    "- Testing Accuracy:  86.94%\n",
    "\n",
    "Dropout is similar to regularization in that it tries to simplify and generalize the model by ignoring some of the neurons during the training, which can prevent overfitting. We see here that different droput rates can either benefit or hurt the model performance, so finding the best rate is key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try combining the best regularized model with the best dropout model.\n",
    "The best regularized model used l2 regularization with a regularization rate of 0.0001 and the best dropout model had a dropout rate of 0.25.\n",
    "\n",
    "### Both Regularization and Droput Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regularized and dropout model\n",
    "def regularized_dropout_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(512, kernel_regularizer=regularizers.l2(0.0001), activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the regularized dropout model\n",
    "model = dropout_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6720 - accuracy: 0.7617 - val_loss: 0.4671 - val_accuracy: 0.8293\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4918 - accuracy: 0.8227 - val_loss: 0.4259 - val_accuracy: 0.8450\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4538 - accuracy: 0.8367 - val_loss: 0.4078 - val_accuracy: 0.8525\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4340 - accuracy: 0.8425 - val_loss: 0.3940 - val_accuracy: 0.8605\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4219 - accuracy: 0.8469 - val_loss: 0.3782 - val_accuracy: 0.8619\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4093 - accuracy: 0.8503 - val_loss: 0.3767 - val_accuracy: 0.8648\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3980 - accuracy: 0.8543 - val_loss: 0.3734 - val_accuracy: 0.8665\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3927 - accuracy: 0.8562 - val_loss: 0.3678 - val_accuracy: 0.8686\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3837 - accuracy: 0.8587 - val_loss: 0.3646 - val_accuracy: 0.8703\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3792 - accuracy: 0.8604 - val_loss: 0.3587 - val_accuracy: 0.8707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201631ad940>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 12.93%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see the model actually had a worse **baseline error of 12.93%** and the following metrics after 10 epochs:\n",
    "- Training Loss: 0.3792\n",
    "- Testing Loss:  0.3587\n",
    "- Training Accuracy: 86.04%\n",
    "- Testing Accuracy:  87.07%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the changes we made did not heavily impact the model performance, with the baseline errors all being between a range of 10.83% and 13.06%. The best model used the l2 regularizer with a regularization factor of 0.0001. Regularization will help select a midpoint between a model with high bias and a model with high variance. It will make the model simpler and closer to an under-fit linear model. Adjusting the rates and other hyperparameters more can produce an even better model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
