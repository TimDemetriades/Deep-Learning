{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3a - Tim Demetriades\n",
    "## NLP\n",
    "9/19/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate deeplearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the needed Python modules and download a requirement for nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\timjr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function to create the bag of words. First it initializes the result_vector with an array of 0s, the length being the size of the text string (also the size of the dictionary). Then the text string is tokenized using the nltk whitespace tokenizer to create a list of all the words in the string. Next the dictionary of words_to_index is created by enumerating words_to_index and this dictionary is printed. Then two for loops are used to iterate over each tokenized word and each word in the enumerated dictionary. If the words match, the corresponding index in the result vector is increased by 1. Finally the result vector is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "    text: a string\n",
    "    words_to_index: a list of the most popular words\n",
    "    dict_size: size of the dictionary\n",
    "\n",
    "    return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    \n",
    "    result_vector = np.zeros(dict_size)\n",
    "\n",
    "    tk = nltk.tokenize.WhitespaceTokenizer()\n",
    "    tokenized_text = tk.tokenize(text)\n",
    "    \n",
    "    enum = enumerate(words_to_index)\n",
    "    indexed_words = dict((i, j) for j, i in enum)\n",
    "    print(indexed_words)\n",
    "    \n",
    "    for word in tokenized_text:\n",
    "        for key, value in indexed_words.items():\n",
    "            if key == word:\n",
    "                index = value\n",
    "                result_vector[index] += 1\n",
    "    \n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'hi how are you'\n",
    "words_to_index = ['hi', 'you', 'me', 'are']\n",
    "dict_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hi': 0, 'you': 1, 'me': 2, 'are': 3}\n"
     ]
    }
   ],
   "source": [
    "result = my_bag_of_words(text, words_to_index, dict_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the enumerated dictionary for words_to_index (the most popular words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the array for the result vector. This makes sense since 'hi', 'you', and 'are' appear once each in both text and words_to_index, with the 1s in the array corresponding to the location of the word in the enumerated dictionary from words_to_index."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
