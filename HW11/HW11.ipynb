{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYMY2IdVQDft"
      },
      "source": [
        "# HW 10 - Tim Demetriades\n",
        "11/14/2021\n",
        "\n",
        "### 1. Suppose you have a daily univariate time series, and you want to forecast the next seven days. Which RNN architecture should you use, i.e. how many neurons you plan to set up?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDkRe6qSQksD"
      },
      "source": [
        "Since we are dealing with a sequence of time series data, it would be a good idea to model this with an RNN. More specifically, to avoid problems with short-term memory (as a result of the vanishing gradient problem), we can use a Long Short-Term Memory (LSTM) architecture. LSTMs are useful with time series data since there can be lags of unknown duration between important events in a time series. The LSTM will recognize important inputs and preserve it as long as it's needed and extract it whenever it is needed. \n",
        "\n",
        "Alternatively, a Gated Recurrent Unit (GRU) architecture could be used, which is similar to LSTM in that it solves the same problem but in a more efficient and simpler way. \n",
        "\n",
        "Since we want to forecast the next seven days of data, we expect to need seven neurons in the output layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYyRzAAPSUuP"
      },
      "source": [
        "### 2. Why do people use Encoder–Decoder RNNs rather than plain sequence-to-sequence RNNs for automatic translation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh0vCWWxScSe"
      },
      "source": [
        "Rather than directly inputing the input sequence to the output sequence when using plain sequence-to-sequence RNNs, with Encoder-Decoder RNNs we are converting the input data into a context semantic vector, which is the word embedding. This is a form of preprocessing that lowers the dimensions of the data into something that is more meaningful. This allows the model to correctly correlate different vectors in order to group similar data (such as words) together. \n",
        "\n",
        "The context vector is of a fixed length (such as 150), compared to the input sequence would could be a variable length. This allows the model to be able to handle different sequences of varying lengths very well.\n",
        "\n",
        "After the encoder creates all the context vectors, the decoder then decodes the context vector into an output sequence. For example, when trying to translate a sentence from one language to another, the encoder will first take the sentence word by word and do word embeddings to create the context vectors. Then the decoder will take these vectors and decode them into an output in the desired languate, translating the input sentence into another language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzstTzxhVK0H"
      },
      "source": [
        "### 3. (optional) Install the tensorflow_addons (pip install tensorflow-addons) and test the Python script of automatic translation (RNN_demo5.ipynb). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW6XMwR_wZD_"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tKBbosYws8K"
      },
      "source": [
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXtYq-J0wwCw",
        "outputId": "28f0482e-be12-496c-d4df-a71ca3dfec20"
      },
      "source": [
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    !pip install -q -U tensorflow-addons\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 20.8 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PvvfnxVwxq3"
      },
      "source": [
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbV2Uamgw2DT",
        "outputId": "9bbb16f3-8cb6-4388-d4b0-a10bdb8c9cb7"
      },
      "source": [
        "if not tf.test.is_gpu_available():\n",
        "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-3e93ce69bb09>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KIaA2SRw6vr"
      },
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlA8_KbhxRyA"
      },
      "source": [
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8Bl38IqxVWL"
      },
      "source": [
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeR4K2epxXuH"
      },
      "source": [
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"nlp\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIRQFGeQxcaQ"
      },
      "source": [
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZy0ycIHxee8"
      },
      "source": [
        "vocab_size = 100\n",
        "embed_size = 10"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28YF5F2nxjT5"
      },
      "source": [
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6XiGAhVxmpt"
      },
      "source": [
        "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
        "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
        "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmqoRsuNxp3B"
      },
      "source": [
        "embeddings = keras.layers.Embedding(vocab_size, embed_size)\n",
        "encoder_embeddings = embeddings(encoder_inputs)\n",
        "decoder_embeddings = embeddings(decoder_inputs)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCT7tCiPxs4X"
      },
      "source": [
        "encoder = keras.layers.LSTM(512, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
        "encoder_state = [state_h, state_c]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajz-N8OuxwaE"
      },
      "source": [
        "sampler = tfa.seq2seq.sampler.TrainingSampler()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoLzOItbx9-8"
      },
      "source": [
        "decoder_cell = keras.layers.LSTMCell(512)\n",
        "output_layer = keras.layers.Dense(vocab_size)\n",
        "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler, output_layer=output_layer)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94rOmFPFyF3h"
      },
      "source": [
        "final_outputs, final_state, final_sequence_lengths = decoder(decoder_embeddings, initial_state=encoder_state, sequence_length=sequence_lengths)\n",
        "Y_proba = tf.nn.softmax(final_outputs.rnn_output)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgB9D2nayNCy"
      },
      "source": [
        "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs, sequence_lengths], outputs=[Y_proba])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0se1Y8KVyTVg"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aon9X7ylyVGE"
      },
      "source": [
        "X = np.random.randint(100, size=10*1000).reshape(1000, 10)\n",
        "Y = np.random.randint(100, size=15*1000).reshape(1000, 15)\n",
        "X_decoder = np.c_[np.zeros((1000, 1)), Y[:, :-1]]\n",
        "seq_lengths = np.full([1000], 15)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qPfqcYjyaHo",
        "outputId": "7c6bdeb4-28ef-41a6-f051-7a2b8cbb80f8"
      },
      "source": [
        "history = model.fit([X, X_decoder, seq_lengths], Y, epochs=2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "32/32 [==============================] - 11s 92ms/step - loss: 4.6052\n",
            "Epoch 2/2\n",
            "32/32 [==============================] - 3s 90ms/step - loss: 4.6037\n"
          ]
        }
      ]
    }
  ]
}